{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import urllib.request\n",
    "np.random.seed(seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 리뷰 개수 : 50000\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"news_summary_more.csv\", nrows = 50000)\n",
    "print('전체 리뷰 개수 :',(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upGrad learner switches to career in ML &amp; Al w...</td>\n",
       "      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Delhi techie wins free food from Swiggy for on...</td>\n",
       "      <td>Kunal Shah's credit card bill payment platform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New Zealand end Rohit Sharma-led India's 12-ma...</td>\n",
       "      <td>New Zealand defeated India by 8 wickets in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aegon life iTerm insurance plan helps customer...</td>\n",
       "      <td>With Aegon Life iTerm Insurance plan, customer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Have known Hirani for yrs, what if MeToo claim...</td>\n",
       "      <td>Speaking about the sexual harassment allegatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rahat Fateh Ali Khan denies getting notice for...</td>\n",
       "      <td>Pakistani singer Rahat Fateh Ali Khan has deni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>India get all out for 92, their lowest ODI tot...</td>\n",
       "      <td>India recorded their lowest ODI total in New Z...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Govt directs Alok Verma to join work 1 day bef...</td>\n",
       "      <td>Weeks after ex-CBI Director Alok Verma told th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Called PM Modi 'sir' 10 times to satisfy his e...</td>\n",
       "      <td>Andhra Pradesh CM N Chandrababu Naidu has said...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cong wins Ramgarh bypoll in Rajasthan, takes t...</td>\n",
       "      <td>Congress candidate Shafia Zubair won the Ramga...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  \\\n",
       "0  upGrad learner switches to career in ML & Al w...   \n",
       "1  Delhi techie wins free food from Swiggy for on...   \n",
       "2  New Zealand end Rohit Sharma-led India's 12-ma...   \n",
       "3  Aegon life iTerm insurance plan helps customer...   \n",
       "4  Have known Hirani for yrs, what if MeToo claim...   \n",
       "5  Rahat Fateh Ali Khan denies getting notice for...   \n",
       "6  India get all out for 92, their lowest ODI tot...   \n",
       "7  Govt directs Alok Verma to join work 1 day bef...   \n",
       "8  Called PM Modi 'sir' 10 times to satisfy his e...   \n",
       "9  Cong wins Ramgarh bypoll in Rajasthan, takes t...   \n",
       "\n",
       "                                                text  \n",
       "0  Saurav Kant, an alumnus of upGrad and IIIT-B's...  \n",
       "1  Kunal Shah's credit card bill payment platform...  \n",
       "2  New Zealand defeated India by 8 wickets in the...  \n",
       "3  With Aegon Life iTerm Insurance plan, customer...  \n",
       "4  Speaking about the sexual harassment allegatio...  \n",
       "5  Pakistani singer Rahat Fateh Ali Khan has deni...  \n",
       "6  India recorded their lowest ODI total in New Z...  \n",
       "7  Weeks after ex-CBI Director Alok Verma told th...  \n",
       "8  Andhra Pradesh CM N Chandrababu Naidu has said...  \n",
       "9  Congress candidate Shafia Zubair won the Ramga...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 열에서 중복을 배제한 유일한 샘플의 수 : 49998\n",
      "Summary 열에서 중복을 배제한 유일한 샘플의 수 : 49971\n"
     ]
    }
   ],
   "source": [
    "print('Text 열에서 중복을 배제한 유일한 샘플의 수 :', data['text'].nunique())\n",
    "print('Summary 열에서 중복을 배제한 유일한 샘플의 수 :', data['headlines'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 49998\n"
     ]
    }
   ],
   "source": [
    "data.drop_duplicates(subset=['text'], inplace=True)\n",
    "print(\"전체 샘플수 :\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headlines    0\n",
      "text         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수 내 사용\n",
    "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\", \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\", \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\", \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 개수 : 179\n",
      "{'did', 't', 'below', 'm', 'ma', 'y', \"haven't\", \"mightn't\", 'her', 'hers', 'an', 'because', 'as', 'didn', 'on', \"you'll\", 'here', 'now', 'when', \"didn't\", 'his', 'your', 'how', 'wouldn', 'he', 'o', 'its', \"wasn't\", 'what', 'that', \"that'll\", 'at', 'been', 'under', 'where', 'be', \"shouldn't\", 'wasn', 'those', 'of', 'any', 'for', 'having', 'shouldn', 'himself', 'with', 'once', 'weren', \"don't\", 'nor', 'whom', 'haven', 'not', \"weren't\", 'had', 'to', \"isn't\", 'are', \"you're\", 'hadn', 'why', 'were', 'a', 'again', 'this', 'i', 'themselves', 'few', 'hasn', 'there', 'both', 'only', 'our', 'so', 'do', 'most', 'me', 'during', 'is', 'itself', 'while', 'after', 'by', 'mightn', 'needn', 'these', \"you've\", 'against', 'was', 'yours', 'yourselves', 'or', \"you'd\", 'such', 'other', 'just', 'which', 'until', 'down', \"couldn't\", 'their', 'have', 'from', 'am', 'aren', 'further', 'has', 'we', 'very', 'and', 'them', 'isn', 've', 'own', \"mustn't\", 'won', 'about', 'up', 'can', 'it', 'all', 'more', 'before', 'does', 'couldn', 'some', 'herself', 's', 'between', 'don', 'through', 'than', 'the', 'if', 'off', 'yourself', \"hasn't\", 'they', 're', \"shan't\", 'but', 'out', 'over', \"should've\", 'no', \"hadn't\", 'she', 'd', 'into', 'ours', 'mustn', 'should', 'you', \"needn't\", 'then', 'myself', \"doesn't\", 'too', 'same', 'll', 'ourselves', 'my', 'in', 'each', 'above', \"she's\", 'who', 'him', \"won't\", \"it's\", 'being', 'ain', 'doesn', 'shan', 'will', 'theirs', \"wouldn't\", \"aren't\", 'doing'}\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "print('불용어 개수 :', len(stop_words))\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수\n",
    "def preprocess_sentence(sentence, remove_stopwords = True):\n",
    "    sentence = sentence.lower() # 텍스트 소문자화\n",
    "    sentence = BeautifulSoup(sentence, \"lxml\").text # <br />, <a href = ...> 등의 html 태그 제거\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열  제거 Ex) my husband (and myself) for => my husband for\n",
    "    sentence = re.sub('\"','', sentence) # 쌍따옴표 \" 제거\n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) # 약어 정규화\n",
    "    sentence = re.sub(r\"'s\\b\",\"\",sentence) # 소유격 제거. Ex) roland's -> roland\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
    "    sentence = re.sub('[m]{2,}', 'mm', sentence) # m이 3개 이상이면 2개로 변경. Ex) ummmmmmm yeah -> umm yeah\n",
    "\n",
    "    # 불용어 제거 (Text)\n",
    "    if remove_stopwords:\n",
    "        tokens = ' '.join(word for word in sentence.split() if not word in stop_words if len(word) > 1)\n",
    "    # 불용어 미제거 (Summary)\n",
    "    else:\n",
    "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "everything bought great infact ordered twice third ordered wasfor mother father\n",
      "great way to start the day\n"
     ]
    }
   ],
   "source": [
    "temp_text = 'Everything I bought was great, infact I ordered twice and the third ordered was<br />for my mother and father.'\n",
    "temp_summary = 'Great way to start (or finish) the day!!!'\n",
    "\n",
    "print(preprocess_sentence(temp_text))\n",
    "print(preprocess_sentence(temp_summary, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['saurav kant alumnus upgrad iiit pg program machine learning artificial intelligence sr systems engineer infosys almost years work experience program upgrad degree career support helped transition data scientist tech mahindra salary hike upgrad online power learning powered lakh careers',\n",
       " 'kunal shah credit card bill payment platform cred gave users chance win free food swiggy one year pranav kaushik delhi techie bagged reward spending cred coins users get one cred coin per rupee bill paid used avail rewards brands like ixigo bookmyshow ubereats cult fit',\n",
       " 'new zealand defeated india wickets fourth odi hamilton thursday win first match five match odi series india lost international match rohit sharma captaincy consecutive victories dating back march match witnessed india getting seventh lowest total odi cricket history',\n",
       " 'aegon life iterm insurance plan customers enjoy tax benefits premiums paid save taxes plan provides life cover age years also customers options insure critical illnesses disability accidental death benefit rider life cover age years',\n",
       " 'speaking sexual harassment allegations rajkumar hirani sonam kapoor said known hirani many years true metoo movement get derailed metoo movement always believe woman case need reserve judgment added hirani accused assistant worked sanju']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text 열 전처리\n",
    "clean_text = []\n",
    "for s in data['text']:\n",
    "    clean_text.append(preprocess_sentence(s))\n",
    "clean_text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['upgrad learner switches to career in ml al with salary hike',\n",
       " 'delhi techie wins free food from swiggy for one year on cred',\n",
       " 'new zealand end rohit sharma led india match winning streak',\n",
       " 'aegon life iterm insurance plan helps customers save tax',\n",
       " 'have known hirani for yrs what if metoo claims are not true sonam']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Headline 열 전처리\n",
    "clean_headline = []\n",
    "for s in data['headlines']:\n",
    "    clean_headline.append(preprocess_sentence(s, 0))\n",
    "clean_headline[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = clean_text\n",
    "data['headlines'] = clean_headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headlines    0\n",
      "text         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 길이가 공백인 샘플은 NULL 값으로 변환\n",
    "data.replace('', np.nan, inplace=True)\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 49998\n"
     ]
    }
   ],
   "source": [
    "data.dropna(axis = 0, inplace = True)\n",
    "print('전체 샘플수 :',(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트의 최소 길이 : 1\n",
      "텍스트의 최대 길이 : 60\n",
      "텍스트의 평균 길이 : 35.11888475539021\n",
      "요약의 최소 길이 : 1\n",
      "요약의 최대 길이 : 16\n",
      "요약의 평균 길이 : 9.546921876875075\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 길이 분포 출력\n",
    "text_len = [len(s.split()) for s in data['text']]\n",
    "headline_len = [len(s.split()) for s in data['headlines']]\n",
    "\n",
    "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
    "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
    "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
    "print('요약의 최소 길이 : {}'.format(np.min(headline_len)))\n",
    "print('요약의 최대 길이 : {}'.format(np.max(headline_len)))\n",
    "print('요약의 평균 길이 : {}'.format(np.mean(headline_len)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(headline_len)\n",
    "plt.title('Headline')\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot(text_len)\n",
    "plt.title('Text')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.title('Headline')\n",
    "plt.hist(headline_len, bins=40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('Text')\n",
    "plt.hist(text_len, bins=40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원문 텍스트는 대체적으로 60이하의 길이를 가진다. 또한, 평균 길이는 35이다.  <br>\n",
    "요약의 경우에는 대체적으로 16이하의 길이를 가지며 평균 길이는 9이다. <br>\n",
    "여기서 패딩의 길이 > 평균 길이보다는 크게 잡아 **각각 38과 11으로 결정한다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_max_len = 38\n",
    "headline_max_len = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def below_threshold_len(max_len, nested_list):\n",
    "  cnt = 0\n",
    "  for s in nested_list:\n",
    "    if(len(s.split()) <= max_len):\n",
    "        cnt = cnt + 1\n",
    "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 38 이하인 샘플의 비율: 0.813472538901556\n"
     ]
    }
   ],
   "source": [
    "below_threshold_len(text_max_len, data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 11 이하인 샘플의 비율: 0.9194567782711308\n"
     ]
    }
   ],
   "source": [
    "below_threshold_len(headline_max_len, data['headlines'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 37327\n"
     ]
    }
   ],
   "source": [
    "data = data[data['text'].apply(lambda x: len(x.split()) <= text_max_len)]\n",
    "data = data[data['headlines'].apply(lambda x: len(x.split()) <= headline_max_len)]\n",
    "print('전체 샘플수 :',(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>new zealand end rohit sharma led india match w...</td>\n",
       "      <td>new zealand defeated india wickets fourth odi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aegon life iterm insurance plan helps customer...</td>\n",
       "      <td>aegon life iterm insurance plan customers enjo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rahat fateh ali khan denies getting notice for...</td>\n",
       "      <td>pakistani singer rahat fateh ali khan denied r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>govt directs alok verma to join work day befor...</td>\n",
       "      <td>weeks ex cbi director alok verma told departme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>called pm modi sir times to satisfy his ego an...</td>\n",
       "      <td>andhra pradesh cm chandrababu naidu said met u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  \\\n",
       "2  new zealand end rohit sharma led india match w...   \n",
       "3  aegon life iterm insurance plan helps customer...   \n",
       "5  rahat fateh ali khan denies getting notice for...   \n",
       "7  govt directs alok verma to join work day befor...   \n",
       "8  called pm modi sir times to satisfy his ego an...   \n",
       "\n",
       "                                                text  \n",
       "2  new zealand defeated india wickets fourth odi ...  \n",
       "3  aegon life iterm insurance plan customers enjo...  \n",
       "5  pakistani singer rahat fateh ali khan denied r...  \n",
       "7  weeks ex cbi director alok verma told departme...  \n",
       "8  andhra pradesh cm chandrababu naidu said met u...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "      <th>decoder_input</th>\n",
       "      <th>decoder_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>new zealand end rohit sharma led india match w...</td>\n",
       "      <td>new zealand defeated india wickets fourth odi ...</td>\n",
       "      <td>sostoken new zealand end rohit sharma led indi...</td>\n",
       "      <td>new zealand end rohit sharma led india match w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aegon life iterm insurance plan helps customer...</td>\n",
       "      <td>aegon life iterm insurance plan customers enjo...</td>\n",
       "      <td>sostoken aegon life iterm insurance plan helps...</td>\n",
       "      <td>aegon life iterm insurance plan helps customer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rahat fateh ali khan denies getting notice for...</td>\n",
       "      <td>pakistani singer rahat fateh ali khan denied r...</td>\n",
       "      <td>sostoken rahat fateh ali khan denies getting n...</td>\n",
       "      <td>rahat fateh ali khan denies getting notice for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>govt directs alok verma to join work day befor...</td>\n",
       "      <td>weeks ex cbi director alok verma told departme...</td>\n",
       "      <td>sostoken govt directs alok verma to join work ...</td>\n",
       "      <td>govt directs alok verma to join work day befor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>called pm modi sir times to satisfy his ego an...</td>\n",
       "      <td>andhra pradesh cm chandrababu naidu said met u...</td>\n",
       "      <td>sostoken called pm modi sir times to satisfy h...</td>\n",
       "      <td>called pm modi sir times to satisfy his ego an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  \\\n",
       "2  new zealand end rohit sharma led india match w...   \n",
       "3  aegon life iterm insurance plan helps customer...   \n",
       "5  rahat fateh ali khan denies getting notice for...   \n",
       "7  govt directs alok verma to join work day befor...   \n",
       "8  called pm modi sir times to satisfy his ego an...   \n",
       "\n",
       "                                                text  \\\n",
       "2  new zealand defeated india wickets fourth odi ...   \n",
       "3  aegon life iterm insurance plan customers enjo...   \n",
       "5  pakistani singer rahat fateh ali khan denied r...   \n",
       "7  weeks ex cbi director alok verma told departme...   \n",
       "8  andhra pradesh cm chandrababu naidu said met u...   \n",
       "\n",
       "                                       decoder_input  \\\n",
       "2  sostoken new zealand end rohit sharma led indi...   \n",
       "3  sostoken aegon life iterm insurance plan helps...   \n",
       "5  sostoken rahat fateh ali khan denies getting n...   \n",
       "7  sostoken govt directs alok verma to join work ...   \n",
       "8  sostoken called pm modi sir times to satisfy h...   \n",
       "\n",
       "                                      decoder_target  \n",
       "2  new zealand end rohit sharma led india match w...  \n",
       "3  aegon life iterm insurance plan helps customer...  \n",
       "5  rahat fateh ali khan denies getting notice for...  \n",
       "7  govt directs alok verma to join work day befor...  \n",
       "8  called pm modi sir times to satisfy his ego an...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 요약 데이터에는 시작 토큰과 종료 토큰을 추가한다.\n",
    "data['decoder_input'] = data['headlines'].apply(lambda x : 'sostoken '+ x)\n",
    "data['decoder_target'] = data['headlines'].apply(lambda x : x + ' eostoken')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = np.array(data['text'])\n",
    "decoder_input = np.array(data['decoder_input'])\n",
    "decoder_target = np.array(data['decoder_target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15565  5198  3030 ... 30403 21243  2732]\n"
     ]
    }
   ],
   "source": [
    "# 훈련 데이터와 테스트 데이터를 분리\n",
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플의 순서를 섞는다\n",
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터의 수 : 7465\n"
     ]
    }
   ],
   "source": [
    "n_of_val = int(len(encoder_input)*0.2)\n",
    "print('테스트 데이터의 수 :',n_of_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 29862\n",
      "훈련 레이블의 개수 : 29862\n",
      "테스트 데이터의 개수 : 7465\n",
      "테스트 레이블의 개수 : 7465\n"
     ]
    }
   ],
   "source": [
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :',len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :',len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :',len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기계가 텍스트를 숫자로 처리할 수 있도록 훈련 데이터와 테스트 데이터에 정수 인코딩\n",
    "src_tokenizer = Tokenizer()\n",
    "src_tokenizer.fit_on_texts(encoder_input_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 43231\n",
      "등장 빈도가 7번 이하인 희귀 단어의 수: 31266\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 11965\n",
      "단어 집합에서 희귀 단어의 비율: 72.32310147810598\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 6.896316649030923\n"
     ]
    }
   ],
   "source": [
    "# 빈도수가 낮은 단어들은 자연어 처리에서 배제\n",
    "# 등장 빈도수가 7회 미만인 단어들이 이 데이터에서 얼만큼의 비중을 차지하는지 확인\n",
    "\n",
    "threshold = 8\n",
    "total_cnt = len(src_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in src_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab = 12000\n",
    "src_tokenizer = Tokenizer(num_words = src_vocab) \n",
    "src_tokenizer.fit_on_texts(encoder_input_train)\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train) \n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3808, 558, 8, 522, 966, 183, 9850, 115, 2902, 1274, 2194, 53, 169, 109, 5637, 301, 3741, 1818, 2903, 2769, 136, 3808, 1, 75, 4254, 393, 6712, 231, 3183, 373, 966, 183], [545, 46, 144, 805, 1866, 3629, 1, 260, 905, 33, 794, 805, 1866, 13, 302, 210, 330, 1105, 2569, 1641, 2569, 1270, 4596, 2603, 53, 805, 1866, 1772, 1430, 5638, 905, 33, 2, 62], [195, 376, 662, 548, 134, 2397, 2065, 165, 662, 189, 2051, 202, 1, 548, 2065, 20, 222, 189, 79, 5171, 6124, 1368, 202, 2, 2940, 2142, 1899, 2941, 279, 482, 430]]\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input_train[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 20047\n",
      "등장 빈도가 6번 이하인 희귀 단어의 수: 14734\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 5313\n",
      "단어 집합에서 희귀 단어의 비율: 73.49728138873647\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 9.866794055615676\n"
     ]
    }
   ],
   "source": [
    "threshold = 7\n",
    "total_cnt = len(tar_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tar_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_vocab = 5000\n",
    "tar_tokenizer = Tokenizer(num_words = tar_vocab) \n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2526, 3, 402, 7, 1257, 6, 1163, 526], [1, 641, 3140, 19, 1382, 3, 23, 442, 1965, 1966, 198], [1, 1753, 1002, 1193, 166, 6, 941, 4, 484], [1, 736, 145, 309, 533, 391, 127, 226, 6, 45, 292], [1, 328, 41, 917, 1468, 3528, 139, 228, 2527]]\n"
     ]
    }
   ],
   "source": [
    "print(decoder_input_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2526, 3, 402, 7, 1257, 6, 1163, 526, 2], [641, 3140, 19, 1382, 3, 23, 442, 1965, 1966, 198, 2], [1753, 1002, 1193, 166, 6, 941, 4, 484, 2], [736, 145, 309, 533, 391, 127, 226, 6, 45, 292, 2], [328, 41, 917, 1468, 3528, 139, 228, 2527, 2]]\n"
     ]
    }
   ],
   "source": [
    "print(decoder_target_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
    "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제할 훈련 데이터의 개수 : 1\n",
      "삭제할 테스트 데이터의 개수 : 0\n"
     ]
    }
   ],
   "source": [
    "# 훈련 데이터와 테스트 데이터에 대해서 요약문의 길이가 1인 경우의\n",
    "# 인덱스를 각각 drop_train과 drop_test에 저장, 이 샘플들을 모두 삭제\n",
    "\n",
    "print('삭제할 훈련 데이터의 개수 :',len(drop_train))\n",
    "print('삭제할 테스트 데이터의 개수 :',len(drop_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 29861\n",
      "훈련 레이블의 개수 : 29861\n",
      "테스트 데이터의 개수 : 7465\n",
      "테스트 레이블의 개수 : 7465\n"
     ]
    }
   ],
   "source": [
    "encoder_input_train = np.delete(encoder_input_train, drop_train, axis=0)\n",
    "decoder_input_train = np.delete(decoder_input_train, drop_train, axis=0)\n",
    "decoder_target_train = np.delete(decoder_target_train, drop_train, axis=0)\n",
    "\n",
    "encoder_input_test = np.delete(encoder_input_test, drop_test, axis=0)\n",
    "decoder_input_test = np.delete(decoder_input_test, drop_test, axis=0)\n",
    "decoder_target_test = np.delete(decoder_target_test, drop_test, axis=0)\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :',len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :',len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :',len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앞서 계산해둔 최대 길이로 맞추어 훈련 데이터와 테스트 데이터에 대해서 패딩 작업\n",
    "\n",
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen = text_max_len, padding='post')\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen = text_max_len, padding='post')\n",
    "decoder_input_train = pad_sequences(decoder_input_train, maxlen = headline_max_len, padding='post')\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen = headline_max_len, padding='post')\n",
    "decoder_input_test = pad_sequences(decoder_input_test, maxlen = headline_max_len, padding='post')\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen = headline_max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\KO SUJIN\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\KO SUJIN\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:4010: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 128\n",
    "hidden_size = 256\n",
    "\n",
    "# 인코더\n",
    "encoder_inputs = Input(shape=(text_max_len,))\n",
    "\n",
    "# 인코더의 임베딩 층\n",
    "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
    "\n",
    "# 인코더의 LSTM 1\n",
    "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4, recurrent_dropout = 0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "# 인코더의 LSTM 2\n",
    "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "# 인코더의 LSTM 3\n",
    "encoder_lstm3 = LSTM(hidden_size, return_state=True, return_sequences=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# 디코더의 임베딩 층\n",
    "dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 디코더의 LSTM\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences = True, return_state = True, dropout = 0.4, recurrent_dropout=0.2)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state = [state_h, state_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 38)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 38, 128)      1536000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 38, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 38, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    640000      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 38, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 5000)   1285000     lstm_3[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 5,300,104\n",
      "Trainable params: 5,300,104\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation = 'softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_outputs) \n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/thushv89/attention_keras/master/src/layers/attention.py\", filename=\"attention.py\")\n",
    "from attention import AttentionLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 38)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 38, 128)      1536000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 38, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 38, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    640000      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 38, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer [(None, None, 256),  131328      lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 512)    0           lstm_3[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 5000)   2565000     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 6,711,432\n",
      "Trainable params: 6,711,432\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 어텐션 층(어텐션 함수)\n",
    "attn_layer = AttentionLayer(name='attention_layer')\n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "# 어텐션의 결과와 디코더의 hidden state들을 연결\n",
    "decoder_concat_input = Concatenate(axis = -1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 29861 samples, validate on 7465 samples\n",
      "WARNING:tensorflow:From C:\\Users\\KO SUJIN\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\KO SUJIN\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Epoch 1/50\n",
      "29861/29861 [==============================] - 351s 12ms/sample - loss: 5.7379 - val_loss: 5.3655\n",
      "Epoch 2/50\n",
      "29861/29861 [==============================] - 348s 12ms/sample - loss: 5.2933 - val_loss: 5.1041\n",
      "Epoch 3/50\n",
      "29861/29861 [==============================] - 347s 12ms/sample - loss: 5.0830 - val_loss: 4.9399\n",
      "Epoch 4/50\n",
      "29861/29861 [==============================] - 348s 12ms/sample - loss: 4.9263 - val_loss: 4.8178\n",
      "Epoch 5/50\n",
      "29861/29861 [==============================] - 350s 12ms/sample - loss: 4.7717 - val_loss: 4.7008\n",
      "Epoch 6/50\n",
      "14336/29861 [=============>................] - ETA: 2:49 - loss: 4.6450"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 2)\n",
    "history = model.fit(x = [encoder_input_train, decoder_input_train], y = decoder_target_train, \\\n",
    "          validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "          batch_size = 256, callbacks=[es], epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_index_to_word = src_tokenizer.index_word # 원문 단어 집합에서 정수 -> 단어를 얻음\n",
    "tar_word_to_index = tar_tokenizer.word_index # 요약 단어 집합에서 단어 -> 정수를 얻음\n",
    "tar_index_to_word = tar_tokenizer.index_word # 요약 단어 집합에서 정수 -> 단어를 얻음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 설계\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(hidden_size,))\n",
    "decoder_state_input_c = Input(shape=(hidden_size,))\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어텐션 함수\n",
    "decoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_inf_concat) \n",
    "\n",
    "# 최종 디코더 모델\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "     # <SOS>에 해당하는 토큰 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_word_to_index['sostoken']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition: # stop_condition이 True가 될 때까지 루프 반복\n",
    "\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = tar_index_to_word[sampled_token_index]\n",
    "\n",
    "        if(sampled_token!='eostoken'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        #  <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_token == 'eostoken'  or len(decoded_sentence.split()) >= (headline_max_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 길이가 1인 타겟 시퀀스를 업데이트\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 상태를 업데이트 합니다.\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2text(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            temp = temp + src_index_to_word[i]+' '\n",
    "    return temp\n",
    "\n",
    "# 요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2summary(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=tar_word_to_index['sostoken']) and i!=tar_word_to_index['eostoken']):\n",
    "            temp = temp + tar_index_to_word[i] + ' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(500, 1000):\n",
    "    print(\"원문 : \",seq2text(encoder_input_test[i]))\n",
    "    print(\"실제 요약문 :\",seq2summary(decoder_input_test[i]))\n",
    "    print(\"예측 요약문 :\",decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
